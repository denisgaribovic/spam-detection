{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e029330c",
   "metadata": {},
   "source": [
    "### Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19847e60",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "### Welcome to my personal project in which I will build a Machine Learning model for spam detection using Naive Bayes and a data set sourced from a Udemy course.\n",
    "\n",
    "### This project involves a number of different tasks like:\n",
    "\n",
    "- Importing data\n",
    "- Preprocessing text data\n",
    "- Noise reduction\n",
    "- Standardization\n",
    "- Feature Extraction\n",
    "- Building a Naive Bayes model\n",
    "- Model evaluation\n",
    "\n",
    "### The goal of my project is to demonstrate the power of Machine Learning models in a real-life scenario, showcasing the effectiveness and potential of Machine Learning to drive business success.\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe6716",
   "metadata": {},
   "source": [
    "### Importing libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cb3776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\d00845\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import nltk # (Natural Language Toolkit) is used for text preprocessing\n",
    "from nltk.corpus import stopwords # provides a list of common stopwords\n",
    "import string # is used to handle string operations, specifically for punctuation removal\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # is used to convert text data into TF-IDF feature vectors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967316f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data\n",
    "df = pd.read_csv('spam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d3909",
   "metadata": {},
   "source": [
    "### Working with text data:\n",
    "\n",
    "- Preprocessing data is essential in text classification tasks for several reasons. By reducing the noise and standardizing the text, the model can focus on the meaningful parts of the text, which can improve the model's performance and generalization ability.\n",
    "\n",
    "- Noise reduction: Punctuation marks often do not contribute to the meaning of the text in the context of text classification and can be considered noise. Stopwords (like \"and\", \"the\", \"is\") are common words that usually do not carry significant meaning and can be removed to reduce dimensionality and noise in the data.\n",
    "\n",
    "- Standardization: Converts all text to a uniform case (usually lowercase), which helps in treating words like \"Apple\" and \"apple\" as the same word.\n",
    "\n",
    "- In order to preprocess the data, a function will be defined which converts text to lowercase, removes punctuation and stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9dddc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                            message\n",
       "0   ham  go jurong point crazy available bugis n great ...\n",
       "1   ham                            ok lar joking wif u oni\n",
       "2  spam  free entry 2 wkly comp win fa cup final tkts 2...\n",
       "3   ham                u dun say early hor u c already say\n",
       "4   ham        nah dont think goes usf lives around though"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['message'] = df['message'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2647b4",
   "metadata": {},
   "source": [
    "### Feature extraction: \n",
    "\n",
    "- Feature extraction is the process of converting text data into numerical features that can be used by machine learning algorithms. TF-IDF (Term Frequency-Inverse Document Frequency) is a popular method for this purpose.\n",
    "\n",
    "- Term Frequency (TF): Measures how frequently a term appears in a document. Higher frequency indicates more importance.\n",
    "\n",
    "- Inverse Document Frequency: Measures how important a term is. Words that occur in many documents have a lower IDF, while rare words have a higher IDF.\n",
    "\n",
    "- The TF-IDF score for each word is calculated by multiplying its TF and IDF scores. This helps balance the term's frequency in a document with how unique it is across all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a65302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['message'])\n",
    "y = df['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f924ada",
   "metadata": {},
   "source": [
    "### Naive Bayes: \n",
    "\n",
    "- Naive Bayes is a family of probabilistic algorithms based on Bayes' Theorem, primarily used for classification tasks. These algorithms operate under the \"naive\" assumption that the features of a dataset are conditionally independent given the class label. \n",
    "\n",
    "- Despite this simplification, Naive Bayes classifiers perform remarkably well in various real-world scenarios, such as spam detection, sentiment analysis, and medical diagnosis. The key advantage of Naive Bayes is its efficiency, both in terms of computational speed and the ability to handle large datasets with ease. \n",
    "\n",
    "- Furthermore, it requires a relatively small amount of training data to estimate the necessary parameters, making it a robust and scalable solution for many applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e9cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each fold: [0.96932185 0.95476575 0.95153473]\n",
      "Average accuracy: 0.958540778701947\n"
     ]
    }
   ],
   "source": [
    "# Initialize K-Fold Cross Validator\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Perform cross-validation and evaluate the model\n",
    "accuracy_scores = cross_val_score(nb_model, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f'Accuracy scores for each fold: {accuracy_scores}')\n",
    "print(f'Average accuracy: {accuracy_scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a8e6ac",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "- This notebook demonstrates a complete workflow for building and evaluating a Naive Bayes classifier to classify email messages as either \"ham\" or \"spam\". \n",
    "\n",
    "- It begins by importing a dataset (spam.csv), preprocesses the text data by converting it to lowercase, removing punctuation, and eliminating stopwords. Next, it uses TF-IDF Vectorization to transform the preprocessed text into numerical features suitable for machine learning. \n",
    "\n",
    "- The code then employs K-Fold Cross Validation with 3 folds to train and evaluate the Multinomial Naive Bayes model on the dataset, calculating accuracy scores for each fold and displaying both individual fold scores and the average accuracy across all folds. This approach ensures robust evaluation of the model's performance while handling text data effectively through preprocessing and feature extraction techniques.\n",
    "\n",
    "- Overall, Naive Bayes was able to successfully detect spam mails with an average accuracy score of 0.95, making it an excellent model for spam detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
